{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 The ML Notebooks Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs) are a type of neural network commonly used for image classification and computer vision tasks. They use convolutional layers to automatically learn spatial hierarchies of features from images, allowing them to identify patterns and objects.\n",
    "\n",
    "In this notebook, we will build a simple CNN using PyTorch to classify images from the CIFAR-10 dataset, which consists of 60,000 32x32 color images in 10 classes. We will also cover data preprocessing, training, evaluation, and data visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Finished importing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the transformations to apply to the data\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(32),\n",
    "        transforms.CenterCrop(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the training and test sets\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 2\n",
    "\n",
    "trainset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform_train\n",
    ")\n",
    "trainloader = DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "\n",
    "testset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform_test\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")\n",
    "# Define the classes of the CIFAR-10 dataset\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "Let's visualize some examples from the CIFAR-10 dataset to get a better sense of what the data looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imshow(img, title=None):\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array((0.485, 0.456, 0.406))\n",
    "    std = np.array((0.229, 0.224, 0.225))\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(trainset), size=(1,)).item()\n",
    "    img, label = trainset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    imshow(img, classes[label])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a batch of training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape)\n",
    "print(labels)\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(images)\n",
    "\n",
    "imshow(out)\n",
    "print(\" \".join(f\"{classes[labels[i]]:5s}\" for i in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the CNN architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Net` class defines the architecture of our network. It has two convolutional layers with 5x5 kernels and max pooling layers with 2x2 kernels. The convolutional layers have 6 and 16 output channels, respectively. The fully connected layers have 120, 84, and 10 output neurons, respectively.\n",
    "\n",
    "The `forward` method defines how the data flows through the network. The input data x is passed through the convolutional and pooling layers, then flattened and passed through the fully connected layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, device, test_loader):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, total=len(test_loader)):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(inputs)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        model.train(mode=was_training)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_per_class(model, device, test_loader, classes):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, total=len(test_loader)):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            # collect the correct predictions for each class\n",
    "            for label, pred in zip(labels, preds):\n",
    "                if label == pred:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "\n",
    "        model.train(mode=was_training)\n",
    "\n",
    "    accuracy_per_class = {classname: 0 for classname in classes}\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        accuracy_per_class[classname] = accuracy\n",
    "\n",
    "    return accuracy_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(model, device, data_loader, classes, num_images=4):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    fig.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, labels) in enumerate(data_loader, 0):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 4, images_so_far)\n",
    "                title = f\"GT: {classes[labels.cpu().data[j]]} \\nP: {classes[preds[j]]}\"\n",
    "                imshow(inputs.cpu().data[j], title)\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    device,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs,\n",
    "):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, total=len(train_loader)):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # predict classes using images from the training set\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        scheduler.step()\n",
    "        # Compute and print the average accuracy for this epoch\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = float(running_corrects) / len(train_loader.dataset)\n",
    "        val_acc = test_accuracy(model, device, val_loader)\n",
    "        print(\n",
    "            f\"loss: {epoch_loss:.4f}  train acc: {epoch_acc:.4f}  val acc: {val_acc:.4f}\"\n",
    "        )\n",
    "        print()\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\"\n",
    "    )\n",
    "    print(f\"Best Acc: {best_acc:4f}\")\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate a neural network model\n",
    "net = Net()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "\n",
    "net = train(\n",
    "    net,\n",
    "    device,\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display predictions for a few images\n",
    "visualize(net, device, testloader, classes, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on testset\n",
    "acc = test_accuracy(net, device, testloader)\n",
    "print(\"Test accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classes that performed well, and the classes that did not perform well\n",
    "acc_per_class = test_accuracy_per_class(net, device, testloader, classes)\n",
    "for classname, accuracy in sorted(\n",
    "    acc_per_class.items(), key=lambda x: x[1], reverse=True\n",
    "):\n",
    "    print(f\"Accuracy for class: {classname:5s} is {accuracy:.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "You have trained a simple CNN model for image classification using pytorch on the CIFAR-10 dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
